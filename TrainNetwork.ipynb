{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchvision \n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from xlwt import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.output_size = 10\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, self.output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(functional.relu(self.conv1(x)))\n",
    "        x = self.pool(functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 400)\n",
    "        x = functional.relu(self.fc(x))\n",
    "        x = functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainLoader(batchsize = 24):\n",
    "    custom_transform = torchvision.transforms.Compose([\n",
    "        # torchvision.transforms.RandomResizedCrop(size=32,scale=(0.5,1.0)), \n",
    "        # torchvision.transforms.RandomPerspective(distortion_scale=0.6,p=1.0),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5 ), (0.5))\n",
    "        ])\n",
    "\n",
    "    train = ImageFolder(root='./trainset', transform=custom_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train,\n",
    "        batch_size = batchsize,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    # print('Number of training images is {}'.format(len(train))) for debug\n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, after mini-batch:    20 loss: 2.104989\n",
      "Epoch: 1, after mini-batch:    40 loss: 1.688766\n",
      "Epoch: 1, after mini-batch:    60 loss: 1.522089\n",
      "Epoch: 1, after mini-batch:    80 loss: 1.440944\n",
      "Epoch: 1, after mini-batch:   100 loss: 2.186397\n",
      "Epoch: 2, after mini-batch:    20 loss: 1.167768\n",
      "Epoch: 2, after mini-batch:    40 loss: 0.777424\n",
      "Epoch: 2, after mini-batch:    60 loss: 1.439861\n",
      "Epoch: 2, after mini-batch:    80 loss: 1.142822\n",
      "Epoch: 2, after mini-batch:   100 loss: 1.345583\n",
      "Epoch: 3, after mini-batch:    20 loss: 0.625060\n",
      "Epoch: 3, after mini-batch:    40 loss: 0.448004\n",
      "Epoch: 3, after mini-batch:    60 loss: 0.689154\n",
      "Epoch: 3, after mini-batch:    80 loss: 0.813249\n",
      "Epoch: 3, after mini-batch:   100 loss: 0.786016\n",
      "Epoch: 4, after mini-batch:    20 loss: 0.374752\n",
      "Epoch: 4, after mini-batch:    40 loss: 0.251475\n",
      "Epoch: 4, after mini-batch:    60 loss: 0.443913\n",
      "Epoch: 4, after mini-batch:    80 loss: 0.572159\n",
      "Epoch: 4, after mini-batch:   100 loss: 0.486310\n",
      "Epoch: 5, after mini-batch:    20 loss: 0.213905\n",
      "Epoch: 5, after mini-batch:    40 loss: 0.162395\n",
      "Epoch: 5, after mini-batch:    60 loss: 0.338643\n",
      "Epoch: 5, after mini-batch:    80 loss: 0.410131\n",
      "Epoch: 5, after mini-batch:   100 loss: 0.334678\n",
      "Epoch: 6, after mini-batch:    20 loss: 0.169519\n",
      "Epoch: 6, after mini-batch:    40 loss: 0.100302\n",
      "Epoch: 6, after mini-batch:    60 loss: 0.196254\n",
      "Epoch: 6, after mini-batch:    80 loss: 0.322489\n",
      "Epoch: 6, after mini-batch:   100 loss: 0.291230\n",
      "Epoch: 7, after mini-batch:    20 loss: 0.132637\n",
      "Epoch: 7, after mini-batch:    40 loss: 0.103902\n",
      "Epoch: 7, after mini-batch:    60 loss: 0.145547\n",
      "Epoch: 7, after mini-batch:    80 loss: 0.263675\n",
      "Epoch: 7, after mini-batch:   100 loss: 0.311175\n",
      "Epoch: 8, after mini-batch:    20 loss: 0.104711\n",
      "Epoch: 8, after mini-batch:    40 loss: 0.113378\n",
      "Epoch: 8, after mini-batch:    60 loss: 0.134861\n",
      "Epoch: 8, after mini-batch:    80 loss: 0.205251\n",
      "Epoch: 8, after mini-batch:   100 loss: 0.282525\n",
      "Epoch: 9, after mini-batch:    20 loss: 0.042543\n",
      "Epoch: 9, after mini-batch:    40 loss: 0.110539\n",
      "Epoch: 9, after mini-batch:    60 loss: 0.091961\n",
      "Epoch: 9, after mini-batch:    80 loss: 0.149667\n",
      "Epoch: 9, after mini-batch:   100 loss: 0.255623\n",
      "Epoch: 10, after mini-batch:    20 loss: 0.032418\n",
      "Epoch: 10, after mini-batch:    40 loss: 0.094842\n",
      "Epoch: 10, after mini-batch:    60 loss: 0.057239\n",
      "Epoch: 10, after mini-batch:    80 loss: 0.115639\n",
      "Epoch: 10, after mini-batch:   100 loss: 0.221078\n",
      "Epoch: 11, after mini-batch:    20 loss: 0.015968\n",
      "Epoch: 11, after mini-batch:    40 loss: 0.092469\n",
      "Epoch: 11, after mini-batch:    60 loss: 0.039290\n",
      "Epoch: 11, after mini-batch:    80 loss: 0.093839\n",
      "Epoch: 11, after mini-batch:   100 loss: 0.196524\n",
      "Epoch: 12, after mini-batch:    20 loss: 0.008775\n",
      "Epoch: 12, after mini-batch:    40 loss: 0.083345\n",
      "Epoch: 12, after mini-batch:    60 loss: 0.025788\n",
      "Epoch: 12, after mini-batch:    80 loss: 0.071766\n",
      "Epoch: 12, after mini-batch:   100 loss: 0.167223\n",
      "Epoch: 13, after mini-batch:    20 loss: 0.006668\n",
      "Epoch: 13, after mini-batch:    40 loss: 0.073112\n",
      "Epoch: 13, after mini-batch:    60 loss: 0.015470\n",
      "Epoch: 13, after mini-batch:    80 loss: 0.054123\n",
      "Epoch: 13, after mini-batch:   100 loss: 0.140430\n",
      "Epoch: 14, after mini-batch:    20 loss: 0.004604\n",
      "Epoch: 14, after mini-batch:    40 loss: 0.063799\n",
      "Epoch: 14, after mini-batch:    60 loss: 0.010714\n",
      "Epoch: 14, after mini-batch:    80 loss: 0.040767\n",
      "Epoch: 14, after mini-batch:   100 loss: 0.126122\n",
      "Epoch: 15, after mini-batch:    20 loss: 0.003070\n",
      "Epoch: 15, after mini-batch:    40 loss: 0.057875\n",
      "Epoch: 15, after mini-batch:    60 loss: 0.008451\n",
      "Epoch: 15, after mini-batch:    80 loss: 0.034215\n",
      "Epoch: 15, after mini-batch:   100 loss: 0.126798\n",
      "Epoch: 16, after mini-batch:    20 loss: 0.002516\n",
      "Epoch: 16, after mini-batch:    40 loss: 0.062025\n",
      "Epoch: 16, after mini-batch:    60 loss: 0.007426\n",
      "Epoch: 16, after mini-batch:    80 loss: 0.030849\n",
      "Epoch: 16, after mini-batch:   100 loss: 0.126107\n",
      "Epoch: 17, after mini-batch:    20 loss: 0.003077\n",
      "Epoch: 17, after mini-batch:    40 loss: 0.062106\n",
      "Epoch: 17, after mini-batch:    60 loss: 0.005601\n",
      "Epoch: 17, after mini-batch:    80 loss: 0.033004\n",
      "Epoch: 17, after mini-batch:   100 loss: 0.123270\n",
      "Epoch: 18, after mini-batch:    20 loss: 0.003336\n",
      "Epoch: 18, after mini-batch:    40 loss: 0.063268\n",
      "Epoch: 18, after mini-batch:    60 loss: 0.004916\n",
      "Epoch: 18, after mini-batch:    80 loss: 0.042468\n",
      "Epoch: 18, after mini-batch:   100 loss: 0.107509\n",
      "Epoch: 19, after mini-batch:    20 loss: 0.001652\n",
      "Epoch: 19, after mini-batch:    40 loss: 0.049289\n",
      "Epoch: 19, after mini-batch:    60 loss: 0.003894\n",
      "Epoch: 19, after mini-batch:    80 loss: 0.045547\n",
      "Epoch: 19, after mini-batch:   100 loss: 0.082839\n",
      "Epoch: 20, after mini-batch:    20 loss: 0.000689\n",
      "Epoch: 20, after mini-batch:    40 loss: 0.035674\n",
      "Epoch: 20, after mini-batch:    60 loss: 0.003539\n",
      "Epoch: 20, after mini-batch:    80 loss: 0.044031\n",
      "Epoch: 20, after mini-batch:   100 loss: 0.074162\n",
      "Epoch: 21, after mini-batch:    20 loss: 0.000615\n",
      "Epoch: 21, after mini-batch:    40 loss: 0.030592\n",
      "Epoch: 21, after mini-batch:    60 loss: 0.003057\n",
      "Epoch: 21, after mini-batch:    80 loss: 0.042760\n",
      "Epoch: 21, after mini-batch:   100 loss: 0.068457\n",
      "Epoch: 22, after mini-batch:    20 loss: 0.000260\n",
      "Epoch: 22, after mini-batch:    40 loss: 0.020356\n",
      "Epoch: 22, after mini-batch:    60 loss: 0.003023\n",
      "Epoch: 22, after mini-batch:    80 loss: 0.031077\n",
      "Epoch: 22, after mini-batch:   100 loss: 0.059989\n",
      "Epoch: 23, after mini-batch:    20 loss: 0.000188\n",
      "Epoch: 23, after mini-batch:    40 loss: 0.016522\n",
      "Epoch: 23, after mini-batch:    60 loss: 0.002586\n",
      "Epoch: 23, after mini-batch:    80 loss: 0.016222\n",
      "Epoch: 23, after mini-batch:   100 loss: 0.057705\n",
      "Epoch: 24, after mini-batch:    20 loss: 0.000121\n",
      "Epoch: 24, after mini-batch:    40 loss: 0.012726\n",
      "Epoch: 24, after mini-batch:    60 loss: 0.001909\n",
      "Epoch: 24, after mini-batch:    80 loss: 0.005716\n",
      "Epoch: 24, after mini-batch:   100 loss: 0.049531\n",
      "Epoch: 25, after mini-batch:    20 loss: 0.000152\n",
      "Epoch: 25, after mini-batch:    40 loss: 0.009516\n",
      "Epoch: 25, after mini-batch:    60 loss: 0.002120\n",
      "Epoch: 25, after mini-batch:    80 loss: 0.005396\n",
      "Epoch: 25, after mini-batch:   100 loss: 0.054389\n",
      "Epoch: 26, after mini-batch:    20 loss: 0.000108\n",
      "Epoch: 26, after mini-batch:    40 loss: 0.005478\n",
      "Epoch: 26, after mini-batch:    60 loss: 0.001866\n",
      "Epoch: 26, after mini-batch:    80 loss: 0.002868\n",
      "Epoch: 26, after mini-batch:   100 loss: 0.047800\n",
      "Epoch: 27, after mini-batch:    20 loss: 0.000136\n",
      "Epoch: 27, after mini-batch:    40 loss: 0.005189\n",
      "Epoch: 27, after mini-batch:    60 loss: 0.001674\n",
      "Epoch: 27, after mini-batch:    80 loss: 0.001964\n",
      "Epoch: 27, after mini-batch:   100 loss: 0.037151\n",
      "Epoch: 28, after mini-batch:    20 loss: 0.000097\n",
      "Epoch: 28, after mini-batch:    40 loss: 0.003644\n",
      "Epoch: 28, after mini-batch:    60 loss: 0.001392\n",
      "Epoch: 28, after mini-batch:    80 loss: 0.002195\n",
      "Epoch: 28, after mini-batch:   100 loss: 0.033040\n",
      "Epoch: 29, after mini-batch:    20 loss: 0.000100\n",
      "Epoch: 29, after mini-batch:    40 loss: 0.003169\n",
      "Epoch: 29, after mini-batch:    60 loss: 0.001265\n",
      "Epoch: 29, after mini-batch:    80 loss: 0.001582\n",
      "Epoch: 29, after mini-batch:   100 loss: 0.022226\n",
      "Epoch: 30, after mini-batch:    20 loss: 0.000092\n",
      "Epoch: 30, after mini-batch:    40 loss: 0.002460\n",
      "Epoch: 30, after mini-batch:    60 loss: 0.001127\n",
      "Epoch: 30, after mini-batch:    80 loss: 0.001390\n",
      "Epoch: 30, after mini-batch:   100 loss: 0.016639\n",
      "Epoch: 31, after mini-batch:    20 loss: 0.000090\n",
      "Epoch: 31, after mini-batch:    40 loss: 0.002225\n",
      "Epoch: 31, after mini-batch:    60 loss: 0.001046\n",
      "Epoch: 31, after mini-batch:    80 loss: 0.001146\n",
      "Epoch: 31, after mini-batch:   100 loss: 0.012186\n",
      "Epoch: 32, after mini-batch:    20 loss: 0.000086\n",
      "Epoch: 32, after mini-batch:    40 loss: 0.001985\n",
      "Epoch: 32, after mini-batch:    60 loss: 0.000921\n",
      "Epoch: 32, after mini-batch:    80 loss: 0.000967\n",
      "Epoch: 32, after mini-batch:   100 loss: 0.008969\n",
      "Epoch: 33, after mini-batch:    20 loss: 0.000074\n",
      "Epoch: 33, after mini-batch:    40 loss: 0.001716\n",
      "Epoch: 33, after mini-batch:    60 loss: 0.000787\n",
      "Epoch: 33, after mini-batch:    80 loss: 0.000851\n",
      "Epoch: 33, after mini-batch:   100 loss: 0.006891\n",
      "Epoch: 34, after mini-batch:    20 loss: 0.000062\n",
      "Epoch: 34, after mini-batch:    40 loss: 0.001464\n",
      "Epoch: 34, after mini-batch:    60 loss: 0.000715\n",
      "Epoch: 34, after mini-batch:    80 loss: 0.000772\n",
      "Epoch: 34, after mini-batch:   100 loss: 0.005456\n",
      "Epoch: 35, after mini-batch:    20 loss: 0.000051\n",
      "Epoch: 35, after mini-batch:    40 loss: 0.001256\n",
      "Epoch: 35, after mini-batch:    60 loss: 0.000650\n",
      "Epoch: 35, after mini-batch:    80 loss: 0.000716\n",
      "Epoch: 35, after mini-batch:   100 loss: 0.004503\n",
      "Epoch: 36, after mini-batch:    20 loss: 0.000042\n",
      "Epoch: 36, after mini-batch:    40 loss: 0.001046\n",
      "Epoch: 36, after mini-batch:    60 loss: 0.000599\n",
      "Epoch: 36, after mini-batch:    80 loss: 0.000654\n",
      "Epoch: 36, after mini-batch:   100 loss: 0.003825\n",
      "Epoch: 37, after mini-batch:    20 loss: 0.000037\n",
      "Epoch: 37, after mini-batch:    40 loss: 0.000936\n",
      "Epoch: 37, after mini-batch:    60 loss: 0.000555\n",
      "Epoch: 37, after mini-batch:    80 loss: 0.000601\n",
      "Epoch: 37, after mini-batch:   100 loss: 0.003303\n",
      "Epoch: 38, after mini-batch:    20 loss: 0.000033\n",
      "Epoch: 38, after mini-batch:    40 loss: 0.000824\n",
      "Epoch: 38, after mini-batch:    60 loss: 0.000508\n",
      "Epoch: 38, after mini-batch:    80 loss: 0.000556\n",
      "Epoch: 38, after mini-batch:   100 loss: 0.002880\n",
      "Epoch: 39, after mini-batch:    20 loss: 0.000029\n",
      "Epoch: 39, after mini-batch:    40 loss: 0.000715\n",
      "Epoch: 39, after mini-batch:    60 loss: 0.000479\n",
      "Epoch: 39, after mini-batch:    80 loss: 0.000528\n",
      "Epoch: 39, after mini-batch:   100 loss: 0.002556\n",
      "Epoch: 40, after mini-batch:    20 loss: 0.000026\n",
      "Epoch: 40, after mini-batch:    40 loss: 0.000649\n",
      "Epoch: 40, after mini-batch:    60 loss: 0.000446\n",
      "Epoch: 40, after mini-batch:    80 loss: 0.000495\n",
      "Epoch: 40, after mini-batch:   100 loss: 0.002270\n",
      "Epoch: 41, after mini-batch:    20 loss: 0.000023\n",
      "Epoch: 41, after mini-batch:    40 loss: 0.000586\n",
      "Epoch: 41, after mini-batch:    60 loss: 0.000420\n",
      "Epoch: 41, after mini-batch:    80 loss: 0.000464\n",
      "Epoch: 41, after mini-batch:   100 loss: 0.002051\n",
      "Epoch: 42, after mini-batch:    20 loss: 0.000021\n",
      "Epoch: 42, after mini-batch:    40 loss: 0.000540\n",
      "Epoch: 42, after mini-batch:    60 loss: 0.000395\n",
      "Epoch: 42, after mini-batch:    80 loss: 0.000440\n",
      "Epoch: 42, after mini-batch:   100 loss: 0.001871\n",
      "Epoch: 43, after mini-batch:    20 loss: 0.000020\n",
      "Epoch: 43, after mini-batch:    40 loss: 0.000494\n",
      "Epoch: 43, after mini-batch:    60 loss: 0.000371\n",
      "Epoch: 43, after mini-batch:    80 loss: 0.000415\n",
      "Epoch: 43, after mini-batch:   100 loss: 0.001725\n",
      "Epoch: 44, after mini-batch:    20 loss: 0.000018\n",
      "Epoch: 44, after mini-batch:    40 loss: 0.000454\n",
      "Epoch: 44, after mini-batch:    60 loss: 0.000350\n",
      "Epoch: 44, after mini-batch:    80 loss: 0.000394\n",
      "Epoch: 44, after mini-batch:   100 loss: 0.001590\n",
      "Epoch: 45, after mini-batch:    20 loss: 0.000017\n",
      "Epoch: 45, after mini-batch:    40 loss: 0.000421\n",
      "Epoch: 45, after mini-batch:    60 loss: 0.000335\n",
      "Epoch: 45, after mini-batch:    80 loss: 0.000379\n",
      "Epoch: 45, after mini-batch:   100 loss: 0.001479\n",
      "Epoch: 46, after mini-batch:    20 loss: 0.000016\n",
      "Epoch: 46, after mini-batch:    40 loss: 0.000392\n",
      "Epoch: 46, after mini-batch:    60 loss: 0.000318\n",
      "Epoch: 46, after mini-batch:    80 loss: 0.000361\n",
      "Epoch: 46, after mini-batch:   100 loss: 0.001382\n",
      "Epoch: 47, after mini-batch:    20 loss: 0.000015\n",
      "Epoch: 47, after mini-batch:    40 loss: 0.000368\n",
      "Epoch: 47, after mini-batch:    60 loss: 0.000301\n",
      "Epoch: 47, after mini-batch:    80 loss: 0.000342\n",
      "Epoch: 47, after mini-batch:   100 loss: 0.001298\n",
      "Epoch: 48, after mini-batch:    20 loss: 0.000014\n",
      "Epoch: 48, after mini-batch:    40 loss: 0.000348\n",
      "Epoch: 48, after mini-batch:    60 loss: 0.000288\n",
      "Epoch: 48, after mini-batch:    80 loss: 0.000329\n",
      "Epoch: 48, after mini-batch:   100 loss: 0.001217\n",
      "Epoch: 49, after mini-batch:    20 loss: 0.000014\n",
      "Epoch: 49, after mini-batch:    40 loss: 0.000327\n",
      "Epoch: 49, after mini-batch:    60 loss: 0.000274\n",
      "Epoch: 49, after mini-batch:    80 loss: 0.000315\n",
      "Epoch: 49, after mini-batch:   100 loss: 0.001149\n",
      "Epoch: 50, after mini-batch:    20 loss: 0.000013\n",
      "Epoch: 50, after mini-batch:    40 loss: 0.000313\n",
      "Epoch: 50, after mini-batch:    60 loss: 0.000263\n",
      "Epoch: 50, after mini-batch:    80 loss: 0.000302\n",
      "Epoch: 50, after mini-batch:   100 loss: 0.001086\n",
      "Epoch: 51, after mini-batch:    20 loss: 0.000012\n",
      "Epoch: 51, after mini-batch:    40 loss: 0.000297\n",
      "Epoch: 51, after mini-batch:    60 loss: 0.000251\n",
      "Epoch: 51, after mini-batch:    80 loss: 0.000290\n",
      "Epoch: 51, after mini-batch:   100 loss: 0.001033\n",
      "Epoch: 52, after mini-batch:    20 loss: 0.000012\n",
      "Epoch: 52, after mini-batch:    40 loss: 0.000283\n",
      "Epoch: 52, after mini-batch:    60 loss: 0.000244\n",
      "Epoch: 52, after mini-batch:    80 loss: 0.000286\n",
      "Epoch: 52, after mini-batch:   100 loss: 0.000979\n",
      "Epoch: 53, after mini-batch:    20 loss: 0.000011\n",
      "Epoch: 53, after mini-batch:    40 loss: 0.000268\n",
      "Epoch: 53, after mini-batch:    60 loss: 0.000232\n",
      "Epoch: 53, after mini-batch:    80 loss: 0.000272\n",
      "Epoch: 53, after mini-batch:   100 loss: 0.000940\n",
      "Epoch: 54, after mini-batch:    20 loss: 0.000011\n",
      "Epoch: 54, after mini-batch:    40 loss: 0.000258\n",
      "Epoch: 54, after mini-batch:    60 loss: 0.000224\n",
      "Epoch: 54, after mini-batch:    80 loss: 0.000263\n",
      "Epoch: 54, after mini-batch:   100 loss: 0.000895\n",
      "Epoch: 55, after mini-batch:    20 loss: 0.000010\n",
      "Epoch: 55, after mini-batch:    40 loss: 0.000248\n",
      "Epoch: 55, after mini-batch:    60 loss: 0.000216\n",
      "Epoch: 55, after mini-batch:    80 loss: 0.000253\n",
      "Epoch: 55, after mini-batch:   100 loss: 0.000861\n"
     ]
    }
   ],
   "source": [
    "wb = Workbook()\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "j = 1\n",
    "sheet1.write(0, 0, 'epoch')\n",
    "sheet1.write(0, 1, 'loss')\n",
    "# sheet1.write(0, 2, 'test_correction')\n",
    "net = Network()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 1e-2)\n",
    "running_loss = 0.0\n",
    "loss1 = 0\n",
    "trainloader = getTrainLoader(batchsize=24)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # correct = calculate_correction()\n",
    "    # print(correct)\n",
    "    for i, mydata in enumerate(trainloader, 0):\n",
    "        inputs, labels = mydata\n",
    "        optimizer.zero_grad()\n",
    "        predicted_labels = net(inputs)\n",
    "        loss = loss_function(predicted_labels, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        loss1 += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print('Epoch: %d, after mini-batch: %5d loss: %.6f' % (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    sheet1.write(j, 1, loss1)\n",
    "    sheet1.write(j, 0, j)\n",
    "    # sheet1.write(j, 2, correct)\n",
    "    j += 1\n",
    "    running_loss = 0.0\n",
    "    loss1 = 0\n",
    "            \n",
    "print('Finished training')\n",
    "torch.save(net.state_dict(), './result.pth')\n",
    "print('The magic is done')\n",
    "# dataiter = iter(testloader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# # Predict the output using the trained neural network\n",
    "# outputs = net(images)\n",
    "\n",
    "# # Normalize the outputs using the Softmax function so that\n",
    "# # we can interpret it as a probability distribution.\n",
    "# sm = nn.Softmax(dim=1)      \n",
    "# sm_outputs = sm(outputs)\n",
    "\n",
    "# # For each output the prediction with the highest probability\n",
    "# # is the predicted label\n",
    "# probs, index = torch.max(sm_outputs, dim=1)\n",
    "# for p, i in zip(probs, index):\n",
    "#     print('True label {0}, Predicted label {0} - {1:.6f}'.format(classes[i], p))\n",
    "if os.path.isfile('train_result.xls'):\n",
    "    os.remove('train_result.xls')\n",
    "wb.save('train_result.xls')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e7576803a044dd1ffd5b972e29be8384eca3c8786984bff8f63f8ba650fae7a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
