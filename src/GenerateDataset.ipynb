{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File: GenerateDataset.ipynb\n",
    "- This file provides some function for generating new training dataset.\n",
    "- This file will generate a dataset according to video provided if you need to update the training set. It will **use the old CNN** to roughly classify the images. **You need to check if there is wrong classification and move the images to the correct class if necessary**. Then you may add them to your old training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as functional\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from ExpNetwork import *\n",
    "\n",
    "custom_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5 ), (0.5))],\n",
    "    )\n",
    "\n",
    "# clarity_transform = torchvision.transforms.Compose(\n",
    "#     [torchvision.transforms.ToTensor(),\n",
    "#      torchvision.transforms.Normalize(0.5, 0.5),\n",
    "#  torchvision.transforms.RandomChoice([torchvision.transforms.ColorJitter(contrast=2),torchvision.transforms.ColorJitter(contrast=0.5)])\n",
    "#  ]\n",
    "# )\n",
    "classes = ('-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'empty')\n",
    "\n",
    "# class Network(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         self.output_size = 12\n",
    "        \n",
    "#         super(Network, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.pool = nn.MaxPool2d(2)\n",
    "#         self.fc = nn.Linear(400, 120)\n",
    "#         self.fc1 = nn.Linear(120, 84)\n",
    "#         self.fc2 = nn.Linear(84, self.output_size)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(functional.relu(self.conv1(x)))\n",
    "#         x = self.pool(functional.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 400)\n",
    "#         x = functional.relu(self.fc(x))\n",
    "#         x = functional.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# class MyDataset_notfromdisk(Dataset): \n",
    "#     def __init__(self, imglist, transform = None, target_transform = None):\n",
    "#         imgs = []\n",
    "#         for onetuple in imglist:\n",
    "#             imgs.append(onetuple) # all tag of images is 1 because we don't use tag\n",
    "#             # imgs.append((img2, 1))\n",
    "#             # imgs.append((neg, 1))\n",
    "#             # imgs.append((img3, 1))\n",
    "#         self.imgs = imgs \n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         fn, label = self.imgs[index]\n",
    "#         img = Image.open(fn) #no need to convert?\n",
    "#         # img = Image.fromarray(fn).convert('RGB') \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img) \n",
    "#         return img, label\n",
    "#     def __len__(self):\n",
    "#         return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEmptyTrainset(rootdirpath, classes):\n",
    "    # format: for instance, rootdirpath=\"./trainset/\"\n",
    "    os.mkdir(rootdirpath)\n",
    "    for oneclass in classes:\n",
    "        os.mkdir(rootdirpath+oneclass+\"/\")\n",
    "\n",
    "def appendImgName(dirpath, appendname):\n",
    "    # format: for instance, rootdirpath=\"./trainset/0/\"\n",
    "    for imgname in os.listdir(dirpath):\n",
    "        os.rename(dirpath+imgname, dirpath+imgname[:-4]+appendname+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clearDir(path, debug=False):\n",
    "#     if os.path.exists(path):\n",
    "#         for i, img in enumerate(os.listdir(path), 1):\n",
    "#             os.remove(path+img)\n",
    "#             if i%1000 == 0 and debug == True:\n",
    "#                 print(\"%d files have been deleted\"%(i))\n",
    "#         if debug == True:\n",
    "#             print(\"All files deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openVideo(videoname):\n",
    "    video = cv2.VideoCapture(\"./\" + videoname)\n",
    "    #check if the video exists\n",
    "    if not video.isOpened():\n",
    "        raise Exception(\"Video cannot be opened.\")\n",
    "    return video\n",
    "\n",
    "def readOneVideo(videoname, dstpath):\n",
    "    os.makedirs(dstpath)\n",
    "    video = openVideo(videoname)\n",
    "    rval = True\n",
    "    frame_cnt = 0\n",
    "    frameid = 1\n",
    "    while rval:\n",
    "        rval, frame = video.read()\n",
    "        frame_cnt += 1\n",
    "        if rval == False:\n",
    "            break\n",
    "        if frame_cnt % 50 != 0: # 0.02s 一张，这里每50张取一张，就是每1s取一张\n",
    "            continue\n",
    "        cv2.imwrite(dstpath+str(frameid)+\".png\", frame)\n",
    "        frameid += 1\n",
    "        \n",
    "\n",
    "def pad_image(im, height, width): #(height width) are the target \n",
    "    im = Image.fromarray(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))  # 把图片从cv2格式转换成Image\n",
    "    w, h = im.size  \n",
    "\n",
    "    if w>=h*width/height:\n",
    "        h1 = int(h*width/w)\n",
    "        im = im.resize((width, h1),  Image.BILINEAR)\n",
    "        im_new = Image.new(mode='RGB', size=(width, height), color=0)\n",
    "        im_new.paste(im, ( 0, (height-h1)//2 ) )\n",
    "    else:\n",
    "        w1 = int(w*height/h)\n",
    "        im = im.resize((w1, height),  Image.BILINEAR)\n",
    "        im_new = Image.new(mode='RGB', size=(width, height), color=0)\n",
    "        im_new.paste(im, ( (width-w1)//2, 0 ) )\n",
    "\n",
    "    im_new = cv2.cvtColor(np.asarray(im_new), cv2.COLOR_RGB2BGR)  # 将Image格式的图片转成np进而转换成cv2格式    \n",
    "    return im_new\n",
    "\n",
    "def processImage(img, templatepath, type):\n",
    "    ned = cv2.imread(templatepath)\n",
    "    result = cv2.matchTemplate(img, ned, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "    test_img = img # test_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \n",
    "\n",
    "    if type == \"R\":\n",
    "        # _, test_img = cv2.threshold(test_img, 150, 255, cv2.THRESH_BINARY)\n",
    "        sample1 = test_img[max_loc[1] : max_loc[1]+26, max_loc[0]-50 : max_loc[0]-24] \n",
    "        sample2 = test_img[max_loc[1] : max_loc[1]+26, max_loc[0]-25 : max_loc[0]+1]\n",
    "        negsample = test_img[max_loc[1] : max_loc[1]+26, max_loc[0]+23 : max_loc[0]+49]\n",
    "        sample3 = test_img[max_loc[1]-1 : max_loc[1]+25, max_loc[0]+48 : max_loc[0]+74]\n",
    "        \n",
    "    elif type == \"Tm\":\n",
    "        # _, test_img = cv2.threshold(test_img, 60, 255, cv2.THRESH_BINARY)\n",
    "        # 以下这个是匹配0标志的\n",
    "        sample1 = test_img[max_loc[1]+4 : max_loc[1]+36, max_loc[0]+27 : max_loc[0]+59] \n",
    "        sample2 = test_img[max_loc[1]+4 : max_loc[1]+36, max_loc[0]+57 : max_loc[0]+89] \n",
    "        negsample = test_img[0:32, 0:32] #useless, since temperature cannot be negative\n",
    "        sample3 = test_img[max_loc[1]+4 : max_loc[1]+36, max_loc[0]+84 : max_loc[0]+116] \n",
    "\n",
    "        # 下面那个是匹配oC标志的\n",
    "        # sample1 = test_img[max_loc[1]+7 : max_loc[1]+40, max_loc[0]-87 : max_loc[0]-64] #之前是+9，+42，-84，-62\n",
    "        # sample2 = test_img[max_loc[1]+7 : max_loc[1]+40, max_loc[0]-60 : max_loc[0]-37] # 之前是+7，+40，-57，-34\n",
    "        # negsample = test_img #useless, since temperature cannot be negative\n",
    "        # sample3 = test_img[max_loc[1]+7 : max_loc[1]+40, max_loc[0]-30 : max_loc[0]-7] #之前是+8，+41，-28，-5\n",
    "    \n",
    "    elif type == \"T\":\n",
    "        # print(\"max_loc=\",max_loc)\n",
    "        # sample = test_img[max_loc[1]-20: max_loc[1]+40, max_loc[0]-140:, ::-1] #just for debug\n",
    "        # _, test_img = cv2.threshold(test_img, 150, 255, cv2.THRESH_BINARY)\n",
    "        sample1 = test_img[max_loc[1]+2 : max_loc[1]+32, max_loc[0]-74 : max_loc[0]-44]\n",
    "        sample2 = test_img[max_loc[1]+2 : max_loc[1]+32, max_loc[0]-38 : max_loc[0]-8]\n",
    "        negsample = test_img[max_loc[1] : max_loc[1]+30, max_loc[0]+33 : max_loc[0]+63]\n",
    "        sample3 = test_img[max_loc[1] : max_loc[1]+30, max_loc[0]+69 : max_loc[0]+99]\n",
    "\n",
    "    elif type == \"I\":\n",
    "        # sample = test_img[max_loc[1]-20: max_loc[1]+40, max_loc[0]-140:, ::-1] #just for debug\n",
    "        # _, test_img = cv2.threshold(test_img, 150, 255, cv2.THRESH_BINARY)\n",
    "        sample1 = test_img[max_loc[1]+4 : max_loc[1]+34, max_loc[0]-74 : max_loc[0]-44] # 之前是+3，+33，-74，-44\n",
    "        sample2 = test_img[max_loc[1]+3 : max_loc[1]+33, max_loc[0]-38 : max_loc[0]-8] # 之前是+2，+32，-38，-8\n",
    "        negsample = test_img[max_loc[1]+3 : max_loc[1]+33, max_loc[0]+35 : max_loc[0]+65]\n",
    "        sample3 = test_img[max_loc[1] : max_loc[1]+30, max_loc[0]+73 : max_loc[0]+103] # 之前是-1，+29，+73，+103\n",
    " \n",
    "    sample1 = pad_image(sample1, 32, 32)\n",
    "    sample2 = pad_image(sample2, 32, 32)\n",
    "    negsample = pad_image(negsample, 32, 32)\n",
    "    sample3 = pad_image(sample3, 32, 32)\n",
    "    \n",
    "    # plt.imshow(sample1)\n",
    "    # plt.show()\n",
    "    # plt.imshow(sample2)\n",
    "    # plt.show()\n",
    "    # plt.imshow(negsample)\n",
    "    # plt.show()\n",
    "    # plt.imshow(sample3)\n",
    "    # plt.show()\n",
    "\n",
    "    return sample1, sample2, negsample, sample3\n",
    "\n",
    "def cutImages(srcdirname, dstdirname):\n",
    "    # Cut images in this folder into single numbers.\n",
    "    #If you want to use this block you need to create this fold and put images into it\n",
    "    os.makedirs(dstdirname)\n",
    "    img_cnt = 0\n",
    "    for imgname in os.listdir(srcdirname):\n",
    "        image = cv2.imread(srcdirname+imgname)\n",
    "        width, length, _ = np.shape(image)\n",
    "        first, second, neg, third = processImage(image[0:width//2, 0:length//3], \"./template images/E1.png\", \"R\") #左上角的表\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt),first)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+1),second)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+2),neg)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+3),third)\n",
    "\n",
    "        first, second, _, third = processImage(image[2*width//5:(width-1), 0:length//2], \"./template images/0.png\", \"Tm\") #左下角的表\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+4),first)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+5),second)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+6),third)\n",
    "\n",
    "        first, second, neg, third = processImage(image[0:width//2, 2*length//5:4*length//5], \"./template images/E2.png\", \"T\") #低真空表\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+7),first)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+8),second)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+9),neg)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+10),third)\n",
    "\n",
    "        first, second, neg, third = processImage(image[0:width//2, 7*length//10:], \"./template images/E3.png\", \"I\") #高真空表\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+11),first)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+12),second)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+13),neg)\n",
    "        cv2.imwrite(dstdirname+\"{i}.png\".format(i = img_cnt+14),third)\n",
    "\n",
    "        img_cnt += 15\n",
    "\n",
    "def loadNet(netpath):\n",
    "    net = MyNetwork()\n",
    "    net.load_state_dict(torch.load(netpath))\n",
    "    return net\n",
    "\n",
    "def classifyImg(srcdirname, dstdirname, net, debugmode = False):\n",
    "    imglist = []\n",
    "    for imgpath in os.listdir(srcdirname):\n",
    "        img = cv2.imread(srcdirname+imgpath, cv2.IMREAD_GRAYSCALE)\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        imglist.append((img, imgpath))\n",
    "    MyData = MyDataset_notfromdisk(imglist=imglist, transform=custom_transform, mode=\"test\")\n",
    "    MyDataLoader = torch.utils.data.DataLoader(MyData, batch_size = 1, shuffle = False)\n",
    "\n",
    "    for batch in MyDataLoader:\n",
    "        img = batch[0]\n",
    "        imgname = batch[1]\n",
    "        outputs = net(img)\n",
    "        sm = nn.Softmax(dim=1)      \n",
    "        sm_outputs = sm(outputs)\n",
    "        probs, index = torch.max(sm_outputs, dim=1)\n",
    "        predict = classes[index[0]]\n",
    "        if debugmode:\n",
    "            plt.imshow(img[0].permute(1, 2, 0))\n",
    "            plt.show()\n",
    "            print(\"img=\",predict)\n",
    "        shutil.move(srcdirname+imgname[0], dstdirname+str(predict)+\"/\"+imgname[0])\n",
    "\n",
    "def addToDataset(srcdirname, dstdirname, copy=False):\n",
    "    # if it is possible to have the same name, rename the image before\n",
    "    # adding to the dataset\n",
    "    # rename to avoid the same name\n",
    "    for dir in os.listdir(srcdirname):\n",
    "        for imgname in os.listdir(srcdirname+dir):\n",
    "            os.rename(srcdirname+dir+\"/\"+imgname, srcdirname+dir+\"/\"+\"new+-\"+imgname)\n",
    "    # move to dstdir\n",
    "    for dir in os.listdir(srcdirname):\n",
    "        for imgname in os.listdir(srcdirname+dir):\n",
    "            if copy:\n",
    "                shutil.copy(srcdirname+dir+\"/\"+imgname, dstdirname+dir+\"/\"+imgname)\n",
    "            else:\n",
    "                shutil.move(srcdirname+dir+\"/\"+imgname, dstdirname+dir+\"/\"+imgname)\n",
    "    # rename to avoid the same name\n",
    "    for dir in os.listdir(dstdirname):\n",
    "        for i, imgname in enumerate(os.listdir(dstdirname+dir), 1):\n",
    "            os.rename(dstdirname+dir+\"/\"+imgname, dstdirname+dir+\"/\"+str(i)+\"-newnew.png\")\n",
    "    # then rename again\n",
    "    for dir in os.listdir(dstdirname):\n",
    "        for i, imgname in enumerate(os.listdir(dstdirname+dir), 1):\n",
    "            os.rename(dstdirname+dir+\"/\"+imgname, dstdirname+dir+\"/\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step: snapshot video\n",
    "# note: it will save to disk\n",
    "readOneVideo(\"../videos/00023_Trim.mp4\", \"../snapshot_trim/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15223\\AppData\\Local\\Temp\\ipykernel_71396\\1838973522.py:31: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  im = im.resize((width, h1),  Image.BILINEAR)\n"
     ]
    }
   ],
   "source": [
    "# second step: cut each snapshot into 15 numbers(or negative sign)\n",
    "# note: it will save to disk\n",
    "cutImages(srcdirname=\"./snapshot/\", dstdirname=\"./00019cut/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformImage(srcdirname, dstdirname):\n",
    "    os.mkdir(dstdirname)\n",
    "    for thres in [70,80,90,100,110,120,130,140,150,160,170,180,190,200]:\n",
    "        os.mkdir(dstdirname+\"thres=\"+str(thres)+\"/\")\n",
    "        for img in os.listdir(srcdirname):\n",
    "            test_img = cv2.imread(srcdirname+img)\n",
    "            test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "            _, test_img = cv2.threshold(test_img, thres, 255, cv2.THRESH_BINARY)\n",
    "            cv2.imwrite(dstdirname+\"thres=\"+str(thres)+\"/\"+img, test_img)\n",
    "            \n",
    "# third step: transform the image into binary image\n",
    "transformImage(srcdirname=\"./00019cut/\", dstdirname=\"./00019transform/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\codes\\Vacuum-Exp\\GenerateDataset.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m classno \u001b[39min\u001b[39;00m classes:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     os\u001b[39m.\u001b[39mmkdir(\u001b[39m\"\u001b[39m\u001b[39m./00019classified/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mdir\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mclassno\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m classifyImg(srcdirname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./00019transform/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mdir\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, dstdirname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./00019classified/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mdir\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, net\u001b[39m=\u001b[39;49mnet)\n",
      "\u001b[1;32md:\\codes\\Vacuum-Exp\\GenerateDataset.ipynb Cell 9\u001b[0m in \u001b[0;36mclassifyImg\u001b[1;34m(srcdirname, dstdirname, net, debugmode)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m     \u001b[39m# plt.imshow(img)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m     \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m     imglist\u001b[39m.\u001b[39mappend((img, imgpath))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m MyData \u001b[39m=\u001b[39m MyDataset_notfromdisk(imglist\u001b[39m=\u001b[39;49mimglist, transform\u001b[39m=\u001b[39;49mcustom_transform, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m MyDataLoader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(MyData, batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, shuffle \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/codes/Vacuum-Exp/GenerateDataset.ipynb#X11sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m MyDataLoader:\n",
      "File \u001b[1;32md:\\codes\\Vacuum-Exp\\ExpNetwork.py:34\u001b[0m, in \u001b[0;36mMyDataset_notfromdisk.__init__\u001b[1;34m(self, imglist, mode, transform)\u001b[0m\n\u001b[0;32m     32\u001b[0m imgs \u001b[39m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m mode\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mfor\u001b[39;00m img1, img2, neg, img3 \u001b[39min\u001b[39;00m imglist:\n\u001b[0;32m     35\u001b[0m         imgs\u001b[39m.\u001b[39mappend((img1, \u001b[39m1\u001b[39m)) \u001b[39m# all tag of images is 1 because we don't use tag\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         imgs\u001b[39m.\u001b[39mappend((img2, \u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# fourth step: load old network, classify images roughly\n",
    "# note: it will move the image from srcpath to dstpath. Classfication may be wrong, so\n",
    "# you have to check and remove some images to correct directory if neccessary\n",
    "net = loadNet(\"./resultv3_gray.pth\")\n",
    "# os.mkdir(\"./00009classified/\")\n",
    "for dir in os.listdir(\"./00019transform/\"):\n",
    "    os.mkdir(\"./00019classified/\"+dir+\"/\")\n",
    "    for classno in classes:\n",
    "        os.mkdir(\"./00019classified/\"+dir+\"/\"+classno+\"/\")\n",
    "    classifyImg(srcdirname=\"./00019transform/\"+dir+\"/\", dstdirname=\"./00019classified/\"+dir+\"/\", net=net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth step: after your checking and reclassification, you may want to shrink\n",
    "# the size of some class of images. For example, if \"7\" class has 100 images, but\n",
    "# \"8\" class has 10 images, you may want to shrink \"7\" class to 10 images to keep\n",
    "# number of images of each class balanced.\n",
    "\n",
    "# Shrink testset or trainset. For example, shrinksize=3 means newsize=oldsize/3 \n",
    "def shrinkDataset(dirname, shrinksize):\n",
    "    path = \"./\" + dirname + \"/\"\n",
    "    # for list in os.listdir(input):\n",
    "    #     list = list + '/'\n",
    "    for i, img in enumerate(os.listdir(path)):\n",
    "        i += 1\n",
    "        if(i % shrinksize != 0):\n",
    "            os.remove(path+img)\n",
    "shrinkDataset(dirname = \"trainsetv3/-\", shrinksize = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth step: after your checking, you could call this function to add those image to\n",
    "# your original dataset\n",
    "addToDataset(srcdirname=\"./trainsetv3/\", dstdirname=\"./trainsetv4/\", copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-: 375\n",
      "0: 491\n",
      "1: 471\n",
      "2: 506\n",
      "3: 596\n",
      "4: 580\n",
      "5: 562\n",
      "6: 558\n",
      "7: 582\n",
      "8: 472\n",
      "9: 466\n",
      "empty: 248\n"
     ]
    }
   ],
   "source": [
    "def countFileNum(dirname):\n",
    "    dirname = \"./\" + dirname + \"/\"\n",
    "    for dir in os.listdir(dirname):\n",
    "        print(dir + \": \" + str(len(os.listdir(dirname+dir))))\n",
    "\n",
    "# countFileNum(\"00011trainset_classified\")\n",
    "countFileNum(\"trainsetv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = loadNet(\"./result.pth\")\n",
    "for dir in [\"thres=130\", \"thres=140\", \"thres=150\", \"thres=160\", \"thres=170\", \"thres=180\", \"thres=190\", \"thres=200\"]:\n",
    "    # for imgname in os.listdir(\"./00009classified/\"+dir+\"/-/\"):\n",
    "        # shutil.copy(\"./00009classified/\"+dir+\"/\"+oneclass+\"/\"+imgname, \"./trainsetv2/\"+oneclass+\"/\"+imgname)\n",
    "    classifyImg(\"./00009classified/\"+dir+\"/empty/\", \"./trainset_notclassified/\", net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createEmptyTrainset(\"./trainsetv4/\",classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendImgName(\"./trainset_notclassified/7/\", \"+\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e7576803a044dd1ffd5b972e29be8384eca3c8786984bff8f63f8ba650fae7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
