{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils import data\n",
    "import torchvision \n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import xlwt\n",
    "from xlwt import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5 ), (0.5))],\n",
    "    )\n",
    "\n",
    "test = ImageFolder(root=\"./testset\", transform=custom_transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test,\n",
    "    batch_size = 4,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "train = ImageFolder(root='./trainset', transform=custom_transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train,\n",
    "    batch_size = 4,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "print('Number of training images is {}'.format(len(train)))\n",
    "print('Number of testing images is {}'.format(len(test)))\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.output_size = 10\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, self.output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(functional.relu(self.conv1(x)))\n",
    "        x = self.pool(functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 400)\n",
    "        x = functional.relu(self.fc(x))\n",
    "        x = functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate how many images are predicted correctly on the testset(total 100)\n",
    "def calculate_correction():\n",
    "    net = Network()\n",
    "    net.load_state_dict(torch.load('./result.pth'))\n",
    "    correction = 0\n",
    "    \n",
    "    input = \"./testset/\"\n",
    "    for list in os.listdir(input):\n",
    "        right_num = eval(list)\n",
    "        list = list + '/'\n",
    "        for img in os.listdir(input+list):\n",
    "            image = cv2.imread(input+list+img)\n",
    "            num = check(image)\n",
    "            if(num == right_num):\n",
    "                correction += 1\n",
    "            else:\n",
    "                print(right_num, num, img)\n",
    "    return correction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = Workbook()\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "j = 1\n",
    "sheet1.write(0, 0, 'epoch')\n",
    "sheet1.write(0, 1, 'loss')\n",
    "sheet1.write(0, 2, 'test_correction')\n",
    "net = Network()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 1e-2)\n",
    "running_loss = 0.0\n",
    "loss1 = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    correct = calculate_correction()\n",
    "    print(correct)\n",
    "    for i, mydata in enumerate(trainloader, 0):\n",
    "        inputs, labels = mydata\n",
    "        optimizer.zero_grad()\n",
    "        predicted_labels = net(inputs)\n",
    "        loss = loss_function(predicted_labels, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        loss1 += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print('Epoch: %d, after mini-batch: %5d loss: %.6f' % (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    sheet1.write(j, 1, loss1)\n",
    "    sheet1.write(j, 0, j)\n",
    "    sheet1.write(j, 2, correct)\n",
    "    j += 1\n",
    "    running_loss = 0.0\n",
    "    loss1 = 0\n",
    "            \n",
    "print('Finished training')\n",
    "torch.save(net.state_dict(), './result.pth')\n",
    "print('The magic is done')\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Predict the output using the trained neural network\n",
    "outputs = net(images)\n",
    "\n",
    "# Normalize the outputs using the Softmax function so that\n",
    "# we can interpret it as a probability distribution.\n",
    "sm = nn.Softmax(dim=1)      \n",
    "sm_outputs = sm(outputs)\n",
    "\n",
    "# For each output the prediction with the highest probability\n",
    "# is the predicted label\n",
    "probs, index = torch.max(sm_outputs, dim=1)\n",
    "for p, i in zip(probs, index):\n",
    "    print('True label {0}, Predicted label {0} - {1:.6f}'.format(classes[i], p))\n",
    "if os.path.isfile('train_result.xls'):\n",
    "    os.remove('train_result.xls')\n",
    "wb.save('train_result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.load_state_dict(torch.load('./result.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(img):\n",
    "    ned = cv2.imread(\"./E.png\")\n",
    "    result = cv2.matchTemplate(img, ned, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "    test_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, test_img = cv2.threshold(test_img, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    sample1 = test_img[max_loc[1] : max_loc[1]+21, max_loc[0]-41 : max_loc[0]-20]\n",
    "    sample1 = cv2.resize(sample1,(32, 32))\n",
    "    sample2 = test_img[max_loc[1] : max_loc[1]+21, max_loc[0]-19 : max_loc[0]+1]\n",
    "    sample2 = cv2.resize(sample2, (32, 32))\n",
    "    sample3 = test_img[max_loc[1] : max_loc[1]+21, max_loc[0]+36 : max_loc[0]+57]\n",
    "    sample3 = cv2.resize(sample3, (32, 32))\n",
    "    return sample1, sample2, sample3\n",
    "\n",
    "def check2(image):#test three images\n",
    "    test_path1 = './1/'\n",
    "    test_path = './1/1/'\n",
    "    first_path = './1/1/first.png'\n",
    "    second_path = './1/1/second.png'\n",
    "    third_path = './1/1/third.png'\n",
    "    show_tag = 0\n",
    "    first, second, third = processImage(image)\n",
    "    if os.path.exists(test_path1):\n",
    "        if os.path.isfile(first_path):\n",
    "            os.remove(first_path)\n",
    "        if os.path.isfile(second_path):\n",
    "            os.remove(second_path)\n",
    "        if os.path.isfile(third_path):\n",
    "            os.remove(third_path)\n",
    "        if os.path.exists(test_path):\n",
    "            os.removedirs(test_path)\n",
    "        \n",
    "    os.makedirs(test_path)\n",
    "    first = cv2.resize(first, (32, 32))\n",
    "    cv2.imwrite(first_path, first)\n",
    "    second = cv2.resize(second, (32, 32))\n",
    "    cv2.imwrite(second_path, second)\n",
    "    third = cv2.resize(third, (32, 32))\n",
    "    cv2.imwrite(third_path, third)\n",
    "    if show_tag:\n",
    "        plt.imshow(first)\n",
    "        plt.show()\n",
    "        plt.imshow(second)\n",
    "        plt.show()\n",
    "        plt.imshow(third)\n",
    "        plt.show()\n",
    "    real_test = ImageFolder(root = test_path1, transform = custom_transform)\n",
    "    real_testloader = torch.utils.data.DataLoader(real_test,\n",
    "        batch_size = 3,\n",
    "        shuffle = False)\n",
    "    dataiter = iter(real_testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = net(images)\n",
    "    sm = nn.Softmax(dim=1)      \n",
    "    sm_outputs = sm(outputs)\n",
    "    probs, index = torch.max(sm_outputs, dim=1)\n",
    "    first = eval(classes[index[0]])\n",
    "    second = eval(classes[index[1]])\n",
    "    third = eval(classes[index[2]])\n",
    "    # print(first)\n",
    "    # print(second)\n",
    "    # print(third)\n",
    "    result = (first + second*0.1)*(10**third)\n",
    "    os.remove(first_path)\n",
    "    os.remove(second_path)\n",
    "    os.remove(third_path)\n",
    "    os.removedirs(test_path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(image):#test one image\n",
    "    test_path1 = './1/'\n",
    "    test_path = './1/1/'\n",
    "    first_path = './1/1/image.png'\n",
    "    if os.path.isfile(first_path):\n",
    "        os.remove(first_path)\n",
    "    if os.path.exists(test_path):\n",
    "        os.removedirs(test_path)\n",
    "            \n",
    "    os.makedirs(test_path)\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    cv2.imwrite(first_path, image)\n",
    "    real_test = ImageFolder(root=test_path1, transform=custom_transform)\n",
    "    real_testloader = torch.utils.data.DataLoader(\n",
    "        real_test,\n",
    "        batch_size = 1,\n",
    "        shuffle = False\n",
    "        )\n",
    "    dataiter = iter(real_testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = net(images)#can't understand why!\n",
    "    sm = nn.Softmax(dim=1)      \n",
    "    sm_outputs = sm(outputs)\n",
    "    _, index = torch.max(sm_outputs, dim=1)\n",
    "    first = eval(classes[index[0]])\n",
    "    result = first\n",
    "    os.remove(first_path)\n",
    "    os.removedirs(test_path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort images automatically\n",
    "input = \"./train_set/\"\n",
    "i = 1000\n",
    "for img in os.listdir(input):\n",
    "    image = cv2.imread(input+img, cv2.IMREAD_UNCHANGED)\n",
    "    a = check(image)\n",
    "    cv2.imwrite(\"./trainset/{result}/{i}.png\".format(i = i, result = a), image)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize images in testset or trainset\n",
    "\n",
    "input = \"./testset/\"\n",
    "for list in os.listdir(input):\n",
    "    list = list + '/'\n",
    "    for img in os.listdir(input+list):\n",
    "        image = cv2.imread(input+list+img)\n",
    "        ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "        image = cv2.resize(image, (32, 32))\n",
    "        cv2.imwrite(input+list+img, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort names of images in testset or trainset\n",
    "\n",
    "input = \"./trainset/\"\n",
    "i = 0\n",
    "for list in os.listdir(input):\n",
    "    list = list + '/'\n",
    "    for img in os.listdir(input+list):\n",
    "        i += 1\n",
    "        os.rename(input+list+img, input+list+'b{i}.png'.format(i = i))\n",
    "        \n",
    "i = 0\n",
    "for list in os.listdir(input):\n",
    "    list = list + '/'\n",
    "    for img in os.listdir(input+list):\n",
    "        i += 1\n",
    "        os.rename(input+list+img, input+list+'{i}.png'.format(i = i))        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink testset or trainset \n",
    "\n",
    "input = \"./trainset/\"\n",
    "i = 0\n",
    "size = 4\n",
    "for list in os.listdir(input):\n",
    "    list = list + '/'\n",
    "    for img in os.listdir(input+list):\n",
    "        i += 1\n",
    "        if(i % size == 0):\n",
    "            continue\n",
    "        else: \n",
    "            os.remove(input+list+img)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(path):# Two layer delete\n",
    "    i = 0\n",
    "    for list in os.listdir(path):\n",
    "        list = list + '/'\n",
    "        for img in os.listdir(path+list):\n",
    "            os.remove(path+list+img)\n",
    "            i += 1\n",
    "            if i%1000 == 0:\n",
    "                print(\"%dimages have been deleted\"%(i))\n",
    "            \n",
    "def delete1(path):# One layer delete\n",
    "    i = 0\n",
    "    for img in os.listdir(path):\n",
    "        os.remove(path+img)\n",
    "        i += 1\n",
    "        if i%1000 == 0:\n",
    "            print(\"%dimages have been deleted\"%(i))\n",
    "\n",
    "show_tag = 0\n",
    "input = \"./sample/\"# Cut images in this folder into single numbers.\n",
    "              #If you want to use this block you need to create this fold and put images into it.\n",
    "delete1(\"./train_set/\")\n",
    "i = 0\n",
    "for list in os.listdir(input):\n",
    "    list = list + '/'\n",
    "    for img in os.listdir(input+list):\n",
    "        image = cv2.imread(input+list+img)\n",
    "        first, second, third = processImage(image)\n",
    "        cv2.imwrite(\"./train_set/{i}.png\".format(i = i),first)\n",
    "        cv2.imwrite(\"./train_set/{i}.png\".format(i = i+1),second)\n",
    "        cv2.imwrite(\"./train_set/{i}.png\".format(i = i+2),third)\n",
    "        i += 3\n",
    "        if i%1000 == 0 or i%1000 == 1 or i%1000 == 2:\n",
    "            print(\"%dimages have been saved\"%(i))\n",
    "        if i%10 == 0 and show_tag:\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            plt.imshow(first)\n",
    "            plt.show()\n",
    "            plt.imshow(second)\n",
    "            plt.show()\n",
    "            plt.imshow(third)\n",
    "            plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete1(\"./train_set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"./sample.MTS\" # Process sample video\n",
    "\n",
    "print(input)\n",
    "video = cv2.VideoCapture(input)\n",
    "wb = Workbook()\n",
    "sheet1 = wb.add_sheet('Sheet 1')\n",
    "\n",
    "\n",
    "frequency = 10\n",
    "if video.isOpened():  # Check whether the video is opened or not\n",
    "    rval, frame = video.read()\n",
    "else:\n",
    "    rval = False\n",
    "print(\"Total frams:\" + str(video.get(7)))\n",
    "print(\"FPS:\" + str(video.get(5)))\n",
    "print(\"Frequency: \" + str(frequency) + \"Hz\")\n",
    "timeF = video.get(5) / frequency\n",
    "print(\"Frams needed to be extracted:\" + str(video.get(7)/timeF))\n",
    "sheet1.write(0, 0, \"Time/s\")\n",
    "sheet1.write(0, 1, \"Pressure/Pa\")\n",
    "print(\"Time/s\", \"Pressure/Pa\")\n",
    "c = 1\n",
    "j = 1\n",
    "while rval:  # Keep reading frames\n",
    "    rval, frame = video.read()\n",
    "    if (c % timeF == 0 and rval):  \n",
    "        result = check2(frame)\n",
    "        print(result, j)\n",
    "        sheet1.write(j, 1, result)\n",
    "        sheet1.write(j, 0, j/10)\n",
    "        j += 1;\n",
    "    c = c + 1\n",
    "\n",
    "if os.path.exists(input+\"_result/\"):\n",
    "    os.removedirs(input+\"_result/\")    \n",
    "os.makedirs(input+\"_result/\")\n",
    "wb.save(input+\"_result/\"+'result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"./sample.MTS\")\n",
    "\n",
    "frequency = 10\n",
    "if video.isOpened():  # Check whether the video is opened or not\n",
    "    rval, frame = video.read()\n",
    "else:\n",
    "    rval = False\n",
    "    \n",
    "print(\"Total frams:\" + str(video.get(7)))\n",
    "print(\"FPS:\" + str(video.get(5)))\n",
    "print(\"Frequency: \" + str(frequency) + \"Hz\")\n",
    "timeF = video.get(5) / frequency\n",
    "print(\"Frams needed to be extracted:\" + str(video.get(7)/timeF))\n",
    "\n",
    "c = 1\n",
    "while rval:  # Keep reading frames\n",
    "    rval, frame = video.read()\n",
    "    c = c + 1\n",
    "    if (c % timeF == 0 and rval):  \n",
    "        cv2.imwrite(\"./sample/{c}.png\".format(c = c/50), frame)\n",
    "        print(\"%.5f\"%((c) / video.get(7) * 100) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3949659082f76c3dce9af69e66ef5cf512c1e4dc52678c6ac146f322361f8d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
